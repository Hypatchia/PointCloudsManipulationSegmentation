{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## PointCloudsSegmentation: Kmeans and DBSCAN\n",
        "\n",
        "* This project aims to explore two popular clustering algorithms, K-means and DBSCAN, for segmenting point clouds.\n",
        "* Point clouds are widely used in various fields, such as computer vision, robotics, and geospatial data analysis.\n",
        "* Segmentation of point clouds is essential for object recognition, scene understanding, and more.\n",
        "\n",
        "### Project Objectives\n",
        "\n",
        "- Implement the K-means clustering algorithm to segment point clouds.\n",
        "- Implement the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm for point cloud segmentation.\n",
        "- Evaluate the performance of both algorithms in terms of accuracy, runtime, and robustness.\n",
        "\n",
        "## Data\n",
        "\n",
        "* Shapenet dataset https://shapenet.org/ for testing and evaluating both algorithms.\n",
        "* The chosen class is the Airplanes Class.\n",
        "* Each airplane's ground truth labels are 4 clusters: head, tail, wings and body of the airplane.\n",
        "\n",
        "## The objective is to be able to cluster the planes into their 3 body parts with clustering results shown visually.\n",
        "\n",
        "## Implementation\n",
        "\n",
        "The project will be implemented using Python and popular libraries such as open3d for point clouds manipukation, NumPy, and scikit-learn for K-means, and scikit-learn for DBSCAN.\n",
        "\n",
        "## Evaluation\n",
        "\n",
        "To assess the performance of the clustering algorithms, we will use the following metrics:\n",
        "\n",
        "- Silhouette Score\n",
        "- Adjusted Rand Index (ARI)\n",
        "- Runtime Analysis\n",
        "- jaccard_scores\n",
        "\n",
        "\n",
        "## Results\n",
        "\n",
        "The results of the segmentation are presented using both K-means and DBSCAN and their performance is compared based on the chosen evaluation metrics.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The project aims to provide insights into the effectiveness of K-means and DBSCAN for point cloud segmentation.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kcP33c61TBoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open3d"
      ],
      "metadata": {
        "id": "WJbD1_0E5_Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Kmeans"
      ],
      "metadata": {
        "id": "-uQlX0sMTF69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cf0qp2iQtg54"
      },
      "outputs": [],
      "source": [
        "# Necessary Imports\n",
        "import numpy as np\n",
        "#pip install open3d\n",
        "import open3d as o3d\n",
        "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "tJpiNGZU6Y3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Shapenet dataset of point clouds\n",
        "dataset_url = \"https://git.io/JiY4i\"\n",
        "\n",
        "dataset_path = keras.utils.get_file(\n",
        "    fname=\"shapenet.zip\",\n",
        "    origin=dataset_url,\n",
        "    cache_subdir=\"datasets\",\n",
        "    hash_algorithm=\"auto\",\n",
        "    extract=True,\n",
        "    archive_format=\"auto\",\n",
        "    cache_dir=\"datasets\",\n",
        ")"
      ],
      "metadata": {
        "id": "t6SqZXX741pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path"
      ],
      "metadata": {
        "id": "J_r1O4LP8nCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "iUVO-pgP8zXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where you want to extract the contents\n",
        "zip_file_path = dataset_path\n",
        "extracted_dir = 'dataset'\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "lRDyiS6G8vAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# View dataset metadata\n",
        "with open(\"/tmp/.keras/datasets/PartAnnotation/metadata.json\") as json_file:\n",
        "    metadata = json.load(json_file)\n",
        "\n",
        "print(metadata)"
      ],
      "metadata": {
        "id": "CpU5C2i1GpqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Airplane_pts_path ='/content/dataset/PartAnnotation/02691156/points/'"
      ],
      "metadata": {
        "id": "eY2t6xt29Qcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List the files in the extracted directory\n",
        "Airplane_pcd_files = os.listdir(Airplane_pts_path)"
      ],
      "metadata": {
        "id": "mb1UBAmX-Y64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Airplane_pcd_files[0:5]"
      ],
      "metadata": {
        "id": "zsUD67nE_EcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the output directory for .pcd files\n",
        "output_directory = 'Data_pcd/'\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "qzIfjqpwDxwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through the list of .pts files\n",
        "for filename in Airplane_pcd_files[:100]:  # Choose the first 100 files\n",
        "    # Construct the full path to the .pts file\n",
        "    pts_path = os.path.join(Airplane_pts_path, filename)\n",
        "\n",
        "    # Read the .pts file (assuming it contains XYZ points)\n",
        "    with open(pts_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    # Parse the points from the .pts file\n",
        "    points = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Ignore empty lines\n",
        "            x, y, z = map(float, line.split())\n",
        "            points.append([x, y, z])\n",
        "\n",
        "    # Create an Open3D point cloud\n",
        "    point_cloud = o3d.geometry.PointCloud()\n",
        "    point_cloud.points = o3d.utility.Vector3dVector(np.array(points))\n",
        "\n",
        "    # Define the path to the output .pcd file\n",
        "    pcd_path = os.path.join(output_directory, f'{filename[:-4]}.pcd')\n",
        "\n",
        "    # Save the point cloud in .pcd format\n",
        "    o3d.io.write_point_cloud(pcd_path, point_cloud)\n",
        "\n",
        "    print(f\"Conversion complete for {filename}. Point cloud saved as {pcd_path}\")"
      ],
      "metadata": {
        "id": "fbw0MDPqD44B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all .pcd files in the directory\n",
        "pcd_files = [os.path.join(output_directory, filename) for filename in os.listdir(output_directory) if filename.endswith('.pcd')][10:20]\n",
        "\n",
        "# Create an empty list to store the loaded point clouds\n",
        "point_clouds = []\n",
        "\n",
        "# Read and append the point clouds to the list\n",
        "for pcd_file in pcd_files:\n",
        "    pcd = o3d.io.read_point_cloud(pcd_file)\n",
        "    point_clouds.append(pcd)\n",
        "    #o3d.visualization.draw_plotly([pcd],window_name=pcd_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "VAg-XWg5_KHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Directory containing ground truth labels\n",
        "labels_directory = '/content/dataset/PartAnnotation/02691156/expert_verified/points_label'\n",
        "\n",
        "# List of .seg files in the directory\n",
        "# Each file is linked to each pcd in order.\n",
        "seg_files = [os.path.join(labels_directory, filename) for filename in os.listdir(labels_directory) if filename.endswith('.seg')]\n",
        "\n",
        "\n",
        "\n",
        "# Initialize a dictionary to store ground truth labels for each point cloud\n",
        "ground_truth_labels = {}\n",
        "# Load ground truth labels for each point cloud\n",
        "for seg_file in seg_files[:100]:\n",
        "    # Extract the name\n",
        "    filename = os.path.splitext(os.path.basename(seg_file))[0]\n",
        "\n",
        "    with open(seg_file, 'r') as file:\n",
        "        labels = [int(line.strip()) for line in file]\n",
        "\n",
        "    ground_truth_labels[filename] = labels"
      ],
      "metadata": {
        "id": "cn2uhhxAPYQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_labels.keys()"
      ],
      "metadata": {
        "id": "eG7eu1DTPhE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get points and transform it to a numpy array:\n",
        "points = [np.asarray(point.points).copy() for point in point_clouds]"
      ],
      "metadata": {
        "id": "UVZkZMtfTWjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points"
      ],
      "metadata": {
        "id": "X4v663H4_tAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_labels.keys()"
      ],
      "metadata": {
        "id": "N-Mutb2UUQpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters =4"
      ],
      "metadata": {
        "id": "iVbCMWyby_Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each point cloud\n",
        "for i in range(len(points)):\n",
        "  # Normalization\n",
        "  scaled_points = StandardScaler().fit_transform(points[i])\n",
        "\n",
        "  # Clustering with K-Means\n",
        "  kmeans_model = KMeans(n_clusters=n_clusters).fit(scaled_points)\n",
        "\n",
        "  # Get labels\n",
        "  cluster_labels = kmeans_model.labels_\n",
        "\n",
        "  # Get the number of colors\n",
        "  n_clusters = len(set(cluster_labels))\n",
        "\n",
        "  # Mapping the labels classes to a color map\n",
        "  colors = plt.get_cmap(\"tab20\")(cluster_labels / (n_clusters if n_clusters > 0 else 1))\n",
        "\n",
        "  # Attribute to noise the black color\n",
        "  colors[cluster_labels < 0] = [0, 0, 0,0]\n",
        "\n",
        "  # Update points colors\n",
        "  pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
        "\n",
        "  # Display the individual point cloud\n",
        "  o3d.visualization.draw_plotly([pcd])"
      ],
      "metadata": {
        "id": "AesButNWTdgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-OZ9xA59KVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each point cloud\n",
        "for i, pcd in enumerate(point_clouds):\n",
        "  # Normalization\n",
        "  scaled_points = StandardScaler().fit_transform(points[i])\n",
        "\n",
        "  # Clustering with K-Means\n",
        "  kmeans_model = KMeans(n_clusters=n_clusters).fit(scaled_points)\n",
        "\n",
        "  # Get labels\n",
        "  cluster_labels = kmeans_model.labels_\n",
        "\n",
        "  # Get the number of colors\n",
        "  n_clusters = len(set(cluster_labels))\n",
        "\n",
        "  # Mapping the labels classes to a color map\n",
        "  colors = plt.get_cmap(\"tab20\")(cluster_labels / (n_clusters if n_clusters > 0 else 1))\n",
        "\n",
        "  # Attribute to noise the black color\n",
        "  colors[cluster_labels < 0] = [0, 0, 0,0]\n",
        "\n",
        "  # Update points colors\n",
        "  pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
        "\n",
        "  # Display the individual point cloud\n",
        "  o3d.visualization.draw_plotly([pcd])"
      ],
      "metadata": {
        "id": "7jVjIuY707IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the output directory for .pcd files\n",
        "new_directory = 'New_pcd/'\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(new_directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "QfFDm1vi2YwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new points (example: random points)\n",
        "new_points = np.random.rand(10, 3)  # 100 new points with (x, y, z) coordinates\n",
        "new_point_clouds =[]\n",
        "# Loop through the list of point clouds and add new points to each\n",
        "for i, point_cloud in enumerate(point_clouds):\n",
        "    # Append the new points to the existing point cloud\n",
        "    combined_points = np.vstack((points[i], new_points))\n",
        "    point_cloud.points = o3d.utility.Vector3dVector(combined_points)\n",
        "\n",
        "    # Save the updated point cloud to a new file or overwrite the original\n",
        "    o3d.io.write_point_cloud(f\"New_pcd/updated_point_cloud{i+1}.pcd\", point_cloud)\n",
        "    o3d.visualization.draw_plotly([point_cloud])\n",
        "    new_point_clouds.append(point_cloud)\n"
      ],
      "metadata": {
        "id": "epDcgixe17f2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_points = [np.asarray(point.points).copy() for point in new_point_clouds]"
      ],
      "metadata": {
        "id": "DqxFwBsK3YI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each point cloud\n",
        "for i in range(len(new_points)):\n",
        "  # Normalization\n",
        "  scaled_points = StandardScaler().fit_transform(new_points[i])\n",
        "\n",
        "  # Clustering with K-Means\n",
        "  kmeans_model = KMeans(n_clusters=n_clusters).fit(scaled_points)\n",
        "\n",
        "  # Get labels\n",
        "  cluster_labels = kmeans_model.labels_\n",
        "\n",
        "  # Get the number of colors\n",
        "  n_clusters = len(set(cluster_labels))\n",
        "\n",
        "  # Mapping the labels classes to a color map\n",
        "  colors = plt.get_cmap(\"tab20\")(cluster_labels / (n_clusters if n_clusters > 0 else 1))\n",
        "\n",
        "  # Attribute to noise the black color\n",
        "  colors[cluster_labels < 0] = [0, 0, 0,0]\n",
        "\n",
        "  # Update points colors\n",
        "  pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
        "\n",
        "  # Display the individual point cloud\n",
        "  o3d.visualization.draw_plotly([pcd])"
      ],
      "metadata": {
        "id": "5d4IfLmN2KD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. DBSCAN"
      ],
      "metadata": {
        "id": "Wb5AaDPjT-fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DBSCAN parameters\n",
        "eps = 0.3  # Maximum distance between two samples for one to be considered as in the neighborhood of the other\n",
        "min_samples = 10  # The number of samples (or total weight) in a neighborhood for a point to be considered as a core point\n",
        "\n",
        "# Iterate through each point cloud\n",
        "for i, pcd in enumerate(point_clouds):\n",
        "    # Normalization\n",
        "    scaled_points = StandardScaler().fit_transform(points[i])\n",
        "\n",
        "    # Clustering with DBSCAN\n",
        "    dbscan_model = DBSCAN(eps=eps, min_samples=min_samples).fit(scaled_points)\n",
        "\n",
        "    # Get labels\n",
        "    cluster_labels = dbscan_model.labels_\n",
        "\n",
        "    # Get the number of colors\n",
        "    n_clusters = len(set(cluster_labels))\n",
        "\n",
        "    # Mapping the labels classes to a color map\n",
        "    colors = plt.get_cmap(\"tab20\")(cluster_labels / (n_clusters if n_clusters > 0 else 1))\n",
        "\n",
        "    # Attribute to noise the black color\n",
        "    colors[cluster_labels == -1] = [0, 0, 0,0]\n",
        "\n",
        "    # Update points colors\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
        "\n",
        "    # Display the individual point cloud\n",
        "    o3d.visualization.draw_plotly([pcd])"
      ],
      "metadata": {
        "id": "ibptRxDPT4DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert\n"
      ],
      "metadata": {
        "id": "XtoQX5WM6CGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/PointCloudsSegmentation.ipynb"
      ],
      "metadata": {
        "id": "3ASL3Ovp6E9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}